"""
LLM ê¸°ë°˜ ì†ì„± ì¶”ì¶œ ëª¨ë“ˆ.

Raw ë¦¬ë·° í…ìŠ¤íŠ¸ì—ì„œ ì†ì„±(Aspect)ì„ ìë™ ì¶”ì¶œí•˜ê³  ê°ì •ì„ ë¶„ì„í•©ë‹ˆë‹¤.
"""

from __future__ import annotations

import hashlib
import json
import os
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from typing import Any

from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field


class Sentiment(str, Enum):
    """ê°ì • ê·¹ì„±."""

    POSITIVE = "positive"
    NEGATIVE = "negative"
    NEUTRAL = "neutral"


class AspectCategory(str, Enum):
    """ì†ì„± ì¹´í…Œê³ ë¦¬."""

    PRICE = "ê°€ê²©/ê°€ì„±ë¹„"
    DESIGN = "ë””ìì¸/ì™¸ê´€"
    SIZE = "ì‚¬ì´ì¦ˆ/ì¹˜ìˆ˜"
    QUALITY = "ì†Œì¬/í’ˆì§ˆ"
    DELIVERY = "ë°°ì†¡/í¬ì¥"
    COLOR = "ìƒ‰ìƒ"
    FUNCTION = "ê¸°ëŠ¥/ì„±ëŠ¥"
    COMFORT = "ì°©ìš©ê°/í¸ì•ˆí•¨"
    DURABILITY = "ë‚´êµ¬ì„±"
    SERVICE = "ì„œë¹„ìŠ¤/ì‘ëŒ€"
    OTHER = "ê¸°íƒ€"


# Pydantic ëª¨ë¸ (Structured Outputìš©)
class ExtractedAspect(BaseModel):
    """ì¶”ì¶œëœ ê°œë³„ ì†ì„±."""

    category: str = Field(description="ì†ì„± ì¹´í…Œê³ ë¦¬ (ê°€ê²©/ê°€ì„±ë¹„, ë””ìì¸/ì™¸ê´€, ì‚¬ì´ì¦ˆ/ì¹˜ìˆ˜, ì†Œì¬/í’ˆì§ˆ, ë°°ì†¡/í¬ì¥, ìƒ‰ìƒ, ê¸°ëŠ¥/ì„±ëŠ¥, ì°©ìš©ê°/í¸ì•ˆí•¨, ë‚´êµ¬ì„±, ì„œë¹„ìŠ¤/ì‘ëŒ€, ê¸°íƒ€)")
    sentiment: str = Field(description="ê°ì • (positive, negative, neutral)")
    text: str = Field(description="í•´ë‹¹ ì†ì„±ì— ëŒ€í•œ ì›ë¬¸ ë°œì·Œ")
    keywords: list[str] = Field(default_factory=list, description="ê´€ë ¨ í‚¤ì›Œë“œ")


class AspectExtractionResult(BaseModel):
    """ì†ì„± ì¶”ì¶œ ê²°ê³¼."""

    aspects: list[ExtractedAspect] = Field(default_factory=list, description="ì¶”ì¶œëœ ì†ì„± ëª©ë¡")
    overall_sentiment: str = Field(description="ì „ì²´ ê°ì • (positive, negative, neutral)")
    confidence: float = Field(ge=0.0, le=1.0, description="ì¶”ì¶œ ì‹ ë¢°ë„ (0.0~1.0)")


@dataclass
class AspectResult:
    """ì†ì„± ì¶”ì¶œ ê²°ê³¼ ë°ì´í„° êµ¬ì¡°."""

    review_text: str
    overall_sentiment: Sentiment
    confidence: float
    aspects: list[dict[str, Any]] = field(default_factory=list)
    metadata: dict[str, Any] = field(default_factory=dict)

    @classmethod
    def from_extraction_result(
        cls,
        review_text: str,
        result: AspectExtractionResult,
        metadata: dict[str, Any] | None = None,
    ) -> "AspectResult":
        """AspectExtractionResultì—ì„œ AspectResult ìƒì„±."""
        aspects = [
            {
                "category": aspect.category,
                "sentiment": aspect.sentiment,
                "text": aspect.text,
                "keywords": aspect.keywords,
            }
            for aspect in result.aspects
        ]

        return cls(
            review_text=review_text,
            overall_sentiment=Sentiment(result.overall_sentiment),
            confidence=result.confidence,
            aspects=aspects,
            metadata=metadata or {},
        )

    def to_dict(self) -> dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜."""
        return {
            "review_text": self.review_text,
            "overall_sentiment": self.overall_sentiment.value,
            "confidence": self.confidence,
            "aspects": self.aspects,
            "metadata": self.metadata,
        }

    def get_aspect_by_category(self, category: str) -> list[dict[str, Any]]:
        """íŠ¹ì • ì¹´í…Œê³ ë¦¬ì˜ ì†ì„± ë°˜í™˜."""
        return [a for a in self.aspects if a["category"] == category]

    def get_positive_aspects(self) -> list[dict[str, Any]]:
        """ê¸ì • ì†ì„± ë°˜í™˜."""
        return [a for a in self.aspects if a["sentiment"] == "positive"]

    def get_negative_aspects(self) -> list[dict[str, Any]]:
        """ë¶€ì • ì†ì„± ë°˜í™˜."""
        return [a for a in self.aspects if a["sentiment"] == "negative"]


# ì†ì„± ì¶”ì¶œ í”„ë¡¬í”„íŠ¸
ASPECT_EXTRACTION_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ì´ì»¤ë¨¸ìŠ¤ ë¦¬ë·° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë¦¬ë·° í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ì–¸ê¸‰ëœ ì†ì„±(Aspect)ê³¼ ê° ì†ì„±ì— ëŒ€í•œ ê°ì •ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.

## ì¶”ì¶œ ëŒ€ìƒ ì†ì„± ì¹´í…Œê³ ë¦¬
- ê°€ê²©/ê°€ì„±ë¹„: ê°€ê²©, ë¹„ìš©, ê°€ì„±ë¹„, í• ì¸ ë“±
- ë””ìì¸/ì™¸ê´€: ë””ìì¸, ëª¨ì–‘, ì™¸ê´€, ìŠ¤íƒ€ì¼ ë“±
- ì‚¬ì´ì¦ˆ/ì¹˜ìˆ˜: ì‚¬ì´ì¦ˆ, í¬ê¸°, ê¸¸ì´, í­, ë‘ê»˜ ë“±
- ì†Œì¬/í’ˆì§ˆ: ì†Œì¬, ì¬ì§ˆ, í’ˆì§ˆ, ë§ˆê° ë“±
- ë°°ì†¡/í¬ì¥: ë°°ì†¡, í¬ì¥, íƒë°°, ë°°ë‹¬ ë“±
- ìƒ‰ìƒ: ìƒ‰ìƒ, ìƒ‰ê¹”, ì»¬ëŸ¬ ë“±
- ê¸°ëŠ¥/ì„±ëŠ¥: ê¸°ëŠ¥, ì„±ëŠ¥, íš¨ê³¼, íš¨ëŠ¥ ë“±
- ì°©ìš©ê°/í¸ì•ˆí•¨: ì°©ìš©ê°, í¸ì•ˆí•¨, ì°©í™”ê° ë“±
- ë‚´êµ¬ì„±: ë‚´êµ¬ì„±, ìˆ˜ëª…, íŠ¼íŠ¼í•¨ ë“±
- ì„œë¹„ìŠ¤/ì‘ëŒ€: ì„œë¹„ìŠ¤, ì‘ëŒ€, ê³ ê°ì„¼í„°, AS ë“±
- ê¸°íƒ€: ìœ„ ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ê¸°íƒ€ ì†ì„±

## ë¶„ì„ ì›ì¹™
1. ë¦¬ë·°ì— ì‹¤ì œë¡œ ì–¸ê¸‰ëœ ì†ì„±ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.
2. ê° ì†ì„±ì— ëŒ€í•œ ê°ì •(ê¸ì •/ë¶€ì •/ì¤‘ë¦½)ì„ ì •í™•íˆ íŒë‹¨í•˜ì„¸ìš”.
3. í•´ë‹¹ ì†ì„±ê³¼ ê´€ë ¨ëœ ì›ë¬¸ì„ ë°œì·Œí•˜ì„¸ìš”.
4. ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.
5. ì†ì„±ì´ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ì„¸ìš”."""


class AspectExtractor:
    """LLM ê¸°ë°˜ ì†ì„± ì¶”ì¶œê¸°."""

    def __init__(
        self,
        model_name: str = "gpt-4o-mini",
        temperature: float = 0.0,
        openai_api_key: str | None = None,
        cache_dir: str | Path | None = None,
        use_cache: bool = True,
    ):
        """
        ì´ˆê¸°í™”.

        Args:
            model_name: LLM ëª¨ë¸ëª…
            temperature: ì˜¨ë„ ì„¤ì •
            openai_api_key: OpenAI API í‚¤
            cache_dir: ìºì‹œ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: ./data/aspect_cache)
            use_cache: ìºì‹œ ì‚¬ìš© ì—¬ë¶€
        """
        self._api_key = openai_api_key or os.getenv("OPENAI_API_KEY")
        if not self._api_key:
            raise ValueError(
                "OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. "
                "OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ê±°ë‚˜ openai_api_key íŒŒë¼ë¯¸í„°ë¥¼ ì „ë‹¬í•˜ì„¸ìš”."
            )

        self.model_name = model_name
        self.temperature = temperature
        self.use_cache = use_cache

        # ìºì‹œ ë””ë ‰í† ë¦¬ ì„¤ì •
        self.cache_dir = Path(cache_dir) if cache_dir else Path("./data/aspect_cache")
        if self.use_cache:
            self.cache_dir.mkdir(parents=True, exist_ok=True)

        # LLM ì´ˆê¸°í™” (with_structured_output ì‚¬ìš©)
        self._llm = ChatOpenAI(
            model=model_name,
            temperature=temperature,
            openai_api_key=self._api_key,
        ).with_structured_output(AspectExtractionResult)

    def _get_cache_key(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì˜ ìºì‹œ í‚¤ ìƒì„±."""
        return hashlib.md5(text.encode()).hexdigest()

    def _get_from_cache(self, text: str) -> AspectResult | None:
        """ìºì‹œì—ì„œ ê²°ê³¼ ì¡°íšŒ."""
        if not self.use_cache:
            return None

        cache_key = self._get_cache_key(text)
        cache_file = self.cache_dir / f"{cache_key}.json"

        if cache_file.exists():
            try:
                with open(cache_file, "r", encoding="utf-8") as f:
                    data = json.load(f)
                return AspectResult(
                    review_text=data["review_text"],
                    overall_sentiment=Sentiment(data["overall_sentiment"]),
                    confidence=data["confidence"],
                    aspects=data["aspects"],
                    metadata=data.get("metadata", {}),
                )
            except Exception:
                return None
        return None

    def _save_to_cache(self, result: AspectResult) -> None:
        """ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥."""
        if not self.use_cache:
            return

        cache_key = self._get_cache_key(result.review_text)
        cache_file = self.cache_dir / f"{cache_key}.json"

        try:
            with open(cache_file, "w", encoding="utf-8") as f:
                json.dump(result.to_dict(), f, ensure_ascii=False, indent=2)
        except Exception:
            pass  # ìºì‹œ ì €ì¥ ì‹¤íŒ¨ëŠ” ë¬´ì‹œ

    def extract(self, review_text: str, metadata: dict[str, Any] | None = None) -> AspectResult:
        """
        ë‹¨ì¼ ë¦¬ë·°ì—ì„œ ì†ì„± ì¶”ì¶œ.

        Args:
            review_text: ë¦¬ë·° í…ìŠ¤íŠ¸
            metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„°

        Returns:
            AspectResult ê°ì²´
        """
        # ìºì‹œ í™•ì¸
        cached = self._get_from_cache(review_text)
        if cached:
            if metadata:
                cached.metadata.update(metadata)
            return cached

        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        messages = [
            {"role": "system", "content": ASPECT_EXTRACTION_SYSTEM_PROMPT},
            {"role": "user", "content": f"ë‹¤ìŒ ë¦¬ë·°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:\n\n{review_text}"},
        ]

        # LLM í˜¸ì¶œ
        try:
            extraction_result: AspectExtractionResult = self._llm.invoke(messages)

            result = AspectResult.from_extraction_result(
                review_text=review_text,
                result=extraction_result,
                metadata=metadata,
            )

            # ìºì‹œ ì €ì¥
            self._save_to_cache(result)

            return result

        except Exception as e:
            # ì—ëŸ¬ ì‹œ ë¹ˆ ê²°ê³¼ ë°˜í™˜
            return AspectResult(
                review_text=review_text,
                overall_sentiment=Sentiment.NEUTRAL,
                confidence=0.0,
                aspects=[],
                metadata={"error": str(e), **(metadata or {})},
            )

    def extract_batch(
        self,
        reviews: list[str | dict[str, Any]],
        show_progress: bool = True,
    ) -> list[AspectResult]:
        """
        ì—¬ëŸ¬ ë¦¬ë·°ì—ì„œ ì†ì„± ì¶”ì¶œ (ë°°ì¹˜ ì²˜ë¦¬).

        Args:
            reviews: ë¦¬ë·° í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” {"text": ..., "metadata": ...} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
            show_progress: ì§„í–‰ ìƒí™© ì¶œë ¥ ì—¬ë¶€

        Returns:
            AspectResult ë¦¬ìŠ¤íŠ¸
        """
        results = []
        total = len(reviews)

        for i, review in enumerate(reviews):
            if isinstance(review, str):
                text = review
                metadata = {}
            else:
                text = review.get("text", "")
                metadata = review.get("metadata", {})

            if show_progress:
                print(f"\rì†ì„± ì¶”ì¶œ ì¤‘: {i + 1}/{total}", end="", flush=True)

            result = self.extract(text, metadata)
            results.append(result)

        if show_progress:
            print()  # ì¤„ë°”ê¿ˆ

        return results

    def get_aspect_statistics(
        self,
        results: list[AspectResult],
    ) -> dict[str, Any]:
        """
        ì†ì„± ì¶”ì¶œ ê²°ê³¼ í†µê³„ ê³„ì‚°.

        Args:
            results: AspectResult ë¦¬ìŠ¤íŠ¸

        Returns:
            í†µê³„ ë”•ì…”ë„ˆë¦¬
        """
        stats = {
            "total_reviews": len(results),
            "overall_sentiment": {
                "positive": 0,
                "negative": 0,
                "neutral": 0,
            },
            "aspect_counts": {},
            "aspect_sentiment": {},
            "avg_confidence": 0.0,
        }

        confidence_sum = 0.0

        for result in results:
            # ì „ì²´ ê°ì • ì§‘ê³„
            sentiment_key = result.overall_sentiment.value
            stats["overall_sentiment"][sentiment_key] += 1
            confidence_sum += result.confidence

            # ì†ì„±ë³„ ì§‘ê³„
            for aspect in result.aspects:
                category = aspect["category"]
                sentiment = aspect["sentiment"]

                # ì†ì„± ê°œìˆ˜
                if category not in stats["aspect_counts"]:
                    stats["aspect_counts"][category] = 0
                stats["aspect_counts"][category] += 1

                # ì†ì„±ë³„ ê°ì •
                if category not in stats["aspect_sentiment"]:
                    stats["aspect_sentiment"][category] = {
                        "positive": 0,
                        "negative": 0,
                        "neutral": 0,
                    }
                stats["aspect_sentiment"][category][sentiment] += 1

        # í‰ê·  ì‹ ë¢°ë„
        if results:
            stats["avg_confidence"] = confidence_sum / len(results)

        # ì†ì„± ê°œìˆ˜ ì •ë ¬ (ë¹ˆë„ìˆœ)
        stats["aspect_counts"] = dict(
            sorted(stats["aspect_counts"].items(), key=lambda x: -x[1])
        )

        return stats

    def clear_cache(self) -> int:
        """
        ìºì‹œ ì‚­ì œ.

        Returns:
            ì‚­ì œëœ íŒŒì¼ ìˆ˜
        """
        if not self.cache_dir.exists():
            return 0

        count = 0
        for cache_file in self.cache_dir.glob("*.json"):
            cache_file.unlink()
            count += 1

        return count


def create_aspect_extractor(
    model_name: str = "gpt-4o-mini",
    temperature: float = 0.0,
    openai_api_key: str | None = None,
    use_cache: bool = True,
) -> AspectExtractor:
    """
    AspectExtractor ìƒì„± í—¬í¼ í•¨ìˆ˜.

    Args:
        model_name: LLM ëª¨ë¸ëª…
        temperature: ì˜¨ë„ ì„¤ì •
        openai_api_key: OpenAI API í‚¤
        use_cache: ìºì‹œ ì‚¬ìš© ì—¬ë¶€

    Returns:
        AspectExtractor ì¸ìŠ¤í„´ìŠ¤
    """
    return AspectExtractor(
        model_name=model_name,
        temperature=temperature,
        openai_api_key=openai_api_key,
        use_cache=use_cache,
    )


def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰."""
    from dotenv import load_dotenv

    # í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
    load_dotenv()

    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    print("=" * 60)
    print("ğŸ” ì†ì„± ì¶”ì¶œê¸° (Aspect Extractor) í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    # í…ŒìŠ¤íŠ¸ ë¦¬ë·°
    test_reviews = [
        "ê°€ê²©ì€ ì¢€ ë¹„ì‹¸ì§€ë§Œ ì†Œì¬ê°€ ì •ë§ ì¢‹ì•„ìš”. ë°°ì†¡ë„ ë¹¨ëìŠµë‹ˆë‹¤.",
        "ë””ìì¸ì´ ì˜ˆì˜ê³  ìƒ‰ìƒë„ ë§ˆìŒì— ë“¤ì–´ìš”. ë‹¤ë§Œ ì‚¬ì´ì¦ˆê°€ ì¡°ê¸ˆ ì‘ë„¤ìš”.",
        "í’ˆì§ˆì´ ê¸°ëŒ€ ì´í•˜ì…ë‹ˆë‹¤. ê°€ê²© ëŒ€ë¹„ ë³„ë¡œì˜ˆìš”. ì‹¤ë§í–ˆì–´ìš”.",
        "ì°©ìš©ê°ì´ í¸í•˜ê³  ê¸°ëŠ¥ë„ ì¢‹ì•„ìš”. ì¬êµ¬ë§¤ ì˜ì‚¬ ìˆìŠµë‹ˆë‹¤!",
        "ë°°ì†¡ì´ ëŠë ¸ì–´ìš”. í¬ì¥ë„ ì—‰ì„±í–ˆê³ ìš”. ì œí’ˆì€ ê´œì°®ì€ë°...",
    ]

    # ì¶”ì¶œê¸° ìƒì„±
    extractor = create_aspect_extractor(use_cache=True)
    print("\nâœ… ì†ì„± ì¶”ì¶œê¸° ìƒì„± ì™„ë£Œ")

    # ë‹¨ì¼ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
    print("\n" + "â”€" * 50)
    print("ğŸ“ ë‹¨ì¼ ë¦¬ë·° ì†ì„± ì¶”ì¶œ í…ŒìŠ¤íŠ¸")
    print("â”€" * 50)

    review = test_reviews[0]
    print(f"\nğŸ“„ ë¦¬ë·°: {review}")

    result = extractor.extract(review)

    print(f"\nğŸ¯ ì „ì²´ ê°ì •: {result.overall_sentiment.value}")
    print(f"ğŸ“Š ì‹ ë¢°ë„: {result.confidence:.2f}")
    print(f"\nğŸ“‹ ì¶”ì¶œëœ ì†ì„± ({len(result.aspects)}ê°œ):")
    for aspect in result.aspects:
        sentiment_emoji = {"positive": "ğŸ˜Š", "negative": "ğŸ˜", "neutral": "ğŸ˜"}
        emoji = sentiment_emoji.get(aspect["sentiment"], "â“")
        print(f"   {emoji} [{aspect['category']}] {aspect['sentiment']}")
        print(f"      ì›ë¬¸: {aspect['text']}")
        if aspect["keywords"]:
            print(f"      í‚¤ì›Œë“œ: {', '.join(aspect['keywords'])}")

    # ë°°ì¹˜ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
    print("\n" + "â”€" * 50)
    print("ğŸ“¦ ë°°ì¹˜ ì†ì„± ì¶”ì¶œ í…ŒìŠ¤íŠ¸")
    print("â”€" * 50)

    results = extractor.extract_batch(test_reviews)
    print(f"\nâœ… {len(results)}ê°œ ë¦¬ë·° ì²˜ë¦¬ ì™„ë£Œ")

    # í†µê³„
    print("\n" + "â”€" * 50)
    print("ğŸ“Š ì†ì„± ì¶”ì¶œ í†µê³„")
    print("â”€" * 50)

    stats = extractor.get_aspect_statistics(results)

    print(f"\nğŸ“Œ ì „ì²´ ë¦¬ë·°: {stats['total_reviews']}ê°œ")
    print(f"ğŸ“Œ í‰ê·  ì‹ ë¢°ë„: {stats['avg_confidence']:.2f}")

    print("\nğŸ­ ì „ì²´ ê°ì • ë¶„í¬:")
    for sentiment, count in stats["overall_sentiment"].items():
        pct = count / stats["total_reviews"] * 100
        bar = "â–ˆ" * int(pct / 5)
        print(f"   {sentiment}: {count}ê°œ ({pct:.1f}%) {bar}")

    print("\nğŸ“‹ ì†ì„±ë³„ ì–¸ê¸‰ ë¹ˆë„:")
    for category, count in stats["aspect_counts"].items():
        print(f"   {category}: {count}íšŒ")

        if category in stats["aspect_sentiment"]:
            sent = stats["aspect_sentiment"][category]
            print(f"      ê¸ì •: {sent['positive']}, ë¶€ì •: {sent['negative']}, ì¤‘ë¦½: {sent['neutral']}")

    print("\n" + "=" * 60)
    print("âœ… ì†ì„± ì¶”ì¶œê¸° í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 60)


if __name__ == "__main__":
    main()
